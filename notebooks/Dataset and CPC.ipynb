{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dataset and CPC.ipynb","provenance":[{"file_id":"188BkhQNwwPJh6Gl2PygTDN8ci5nsR8tI","timestamp":1618786429146}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EBsI8as2VpzJ"},"source":["# Dataset and CPC Sandbox\n","\n","*April 16, 2021*\n","\n","This notebook achieves two tasks:\n","1. Dataset curation -- we want to organize the MusicNet dataset by instrument type\n","2. Preliminary CPC training/testing -- we want to get an implementation of the CPC model working on the MusicNet dataset\n","\n","**References** \n","1. [Script to download raw MusicNet data (Github)](https://github.com/jthickstun/pytorch_musicnet)\n","2. [UMT's MusicNet data loader (Github)](https://github.com/facebookresearch/music-translation)\n","3. [MusicNet Documentation](https://homes.cs.washington.edu/~thickstn/musicnet.html)\n","4. [CPC Implementation (Github)](https://github.com/jefflai108/Contrastive-Predictive-Coding-PyTorch)"]},{"cell_type":"markdown","metadata":{"id":"snusK-uDXH6Z"},"source":["## 1. Dataset Curation"]},{"cell_type":"code","metadata":{"id":"8J2H2uzKYJzN"},"source":["from __future__ import print_function\n","from subprocess import call\n","import torch.utils.data as data\n","import os, mmap\n","import os.path\n","import pickle\n","import errno\n","import csv\n","import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import subprocess\n","import h5py\n","\n","from shutil import copy, move\n","from intervaltree import IntervalTree\n","from scipy.io import wavfile\n","from tqdm import tqdm\n","from pathlib import Path\n","from tempfile import NamedTemporaryFile\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mppMXxkr4J0g"},"source":["### Downloading MusicNet data\n","We follow a similar setup process to [Universal Music Translation Network](https://github.com/facebookresearch/music-translation)\n","1. Download raw data from [https://homes.cs.washington.edu/~thickstn/media/](https://homes.cs.washington.edu/~thickstn/media/)\n","2. Extract files into `train_data`, `train_labels`, `test_data`, `test_labels` subdirectories\n","3. Parse the raw data and organize them by either `ensemble` or `composer`\n","4. Split into train/test/val sets\n","5. (Optional) Perform preprocessing on the audio for training"]},{"cell_type":"code","metadata":{"id":"kiv7BV6a4PGU"},"source":["def _check_exists(root):\n","    return os.path.exists(os.path.join(root, \"train_data\")) and \\\n","        os.path.exists(os.path.join(root, \"test_data\")) and \\\n","        os.path.exists(os.path.join(root, \"train_labels\")) and \\\n","        os.path.exists(os.path.join(root, \"test_labels\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVuIt-Sh0A4x"},"source":["def download_data(root):\n","    \"\"\"Download MusicNet data at root.\n","    Adapted from https://github.com/jthickstun/pytorch_musicnet\n","\n","    Parameters\n","    ----------\n","    root : str, Path\n","        Directory to download MusicNet data. Will create train_data, train_labels,\n","        test_data, test_labels, and raw subdirectories.\n","    \"\"\"\n","    from six.moves import urllib\n","\n","    if _check_exists(root):\n","        return\n","\n","    try:\n","        os.makedirs(os.path.join(root, \"raw\"))\n","    except OSError as e:\n","        if e.errno == errno.EEXIST:\n","            pass\n","        else:\n","            raise\n","    \n","    # Download musicnet.tar.gz\n","    url = \"https://homes.cs.washington.edu/~thickstn/media/musicnet.tar.gz\"\n","    filename = url.rpartition('/')[2]\n","    file_path = os.path.join(root, \"raw\", filename)\n","    if not os.path.exists(file_path):\n","        print(f\"Downloading {url}\")\n","        data = urllib.request.urlopen(url)\n","        with open(file_path, 'wb') as f:\n","            # stream the download to disk (it might not fit in memory!)\n","            while True:\n","                chunk = data.read(16*1024)\n","                if not chunk:\n","                    break\n","                f.write(chunk)\n","\n","    # Unpack musicnet.tar.gz\n","    extracted_folders = [\"train_data\", \"train_labels\", \"test_data\", \"test_labels\"]\n","    if not all(map(lambda f: os.path.exists(os.path.join(root, f)), extracted_folders)):\n","        print('Extracting ' + filename)\n","        if call([\"tar\", \"-xf\", file_path, '-C', root, '--strip', '1']) != 0:\n","            raise OSError(\"Failed tarball extraction\")\n","\n","    # Download musicnet_metadata.csv\n","    url = \"https://homes.cs.washington.edu/~thickstn/media/musicnet_metadata.csv\"\n","    metadata = urllib.request.urlopen(url)\n","    with open(os.path.join(root, 'musicnet_metadata.csv'), 'wb') as f:\n","        while True:\n","            chunk = metadata.read(16*1024)\n","            if not chunk:\n","                break\n","            f.write(chunk)\n","\n","    print('Download Complete')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Me9cehOQXpom","executionInfo":{"status":"ok","timestamp":1618768033124,"user_tz":240,"elapsed":404,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"d01a3dfa-a5a9-4344-a24a-6b347a27041a"},"source":["root = \"/content/musicnet\"\n","download_data(root)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Download Complete\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"v2h5VwReIVmX","executionInfo":{"status":"ok","timestamp":1618770936452,"user_tz":240,"elapsed":413,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"8a53c0a8-0bdc-4029-b48d-cc0090ca5f5f"},"source":["metadata = pd.read_csv('/content/musicnet/musicnet_metadata.csv')\n","metadata.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>composer</th>\n","      <th>composition</th>\n","      <th>movement</th>\n","      <th>ensemble</th>\n","      <th>source</th>\n","      <th>transcriber</th>\n","      <th>catalog_name</th>\n","      <th>seconds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1727</td>\n","      <td>Schubert</td>\n","      <td>Piano Quintet in A major</td>\n","      <td>2. Andante</td>\n","      <td>Piano Quintet</td>\n","      <td>European Archive</td>\n","      <td>http://tirolmusic.blogspot.com/</td>\n","      <td>OP114</td>\n","      <td>447</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1728</td>\n","      <td>Schubert</td>\n","      <td>Piano Quintet in A major</td>\n","      <td>3. Scherzo: Presto</td>\n","      <td>Piano Quintet</td>\n","      <td>European Archive</td>\n","      <td>http://tirolmusic.blogspot.com/</td>\n","      <td>OP114</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1729</td>\n","      <td>Schubert</td>\n","      <td>Piano Quintet in A major</td>\n","      <td>4. Andantino - Allegretto</td>\n","      <td>Piano Quintet</td>\n","      <td>European Archive</td>\n","      <td>http://tirolmusic.blogspot.com/</td>\n","      <td>OP114</td>\n","      <td>444</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1730</td>\n","      <td>Schubert</td>\n","      <td>Piano Quintet in A major</td>\n","      <td>5. Allegro giusto</td>\n","      <td>Piano Quintet</td>\n","      <td>European Archive</td>\n","      <td>http://tirolmusic.blogspot.com/</td>\n","      <td>OP114</td>\n","      <td>368</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1733</td>\n","      <td>Schubert</td>\n","      <td>Piano Sonata in A major</td>\n","      <td>2. Andantino</td>\n","      <td>Solo Piano</td>\n","      <td>Museopen</td>\n","      <td>Segundo G. Yogore</td>\n","      <td>D959</td>\n","      <td>546</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id  composer  ... catalog_name seconds\n","0  1727  Schubert  ...        OP114     447\n","1  1728  Schubert  ...        OP114     251\n","2  1729  Schubert  ...        OP114     444\n","3  1730  Schubert  ...        OP114     368\n","4  1733  Schubert  ...         D959     546\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"AVAiHVQIGhKm"},"source":["def process_labels(root, path):\n","    \"\"\"Parse label CSVs for MusicNet and store in a dictionary\n","    containing IntervalTrees \n","    \n","    Parameters\n","    ----------\n","    root : str, Path\n","        Absolute path to root of data directory\n","    \n","    path : str, Path\n","        Subdirectory in root to parse labels from\n","\n","    Returns\n","    -------\n","    trees : dict\n","        Dictionary of IntervalTrees for each CSV found in the specified\n","        subdirectory path.\n","    \"\"\"\n","    trees = dict()\n","    for item in os.listdir(os.path.join(root,path)):\n","        if not item.endswith('.csv'): continue\n","        uid = int(item[:-4])\n","        tree = IntervalTree()\n","        with open(os.path.join(root, path, item), 'r') as f:\n","            reader = csv.DictReader(f, delimiter=',')\n","            for label in reader:\n","                start_time = int(label['start_time'])\n","                end_time = int(label['end_time'])\n","                instrument = int(label['instrument'])\n","                note = int(label['note'])\n","                start_beat = float(label['start_beat'])\n","                end_beat = float(label['end_beat'])\n","                note_value = label['note_value']\n","                tree[start_time:end_time] = (instrument,note,start_beat,end_beat,note_value)\n","        trees[uid] = tree\n","    return trees"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jvkLlG7GnCy"},"source":["train_labels = process_labels(root, \"train_labels\")\n","test_labels = process_labels(root, \"test_labels\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBFmLbBkb4Cf"},"source":["def curate_data(root, destination, metadata, groupby='composer', disable_progress_bar=True):\n","    \"\"\"Organize original dataset structure into \n","    \n","    \"\"\"\n","    if not hasattr(metadata, \"columns\"):\n","        raise AttributeError('metadata must have a columns attribute')\n","\n","    if groupby not in metadata.columns:\n","        raise ValueError(f'{groupby} column is not in metadata')\n","\n","    root = Path(root)\n","    destination = Path(destination)\n","\n","    if not os.path.isabs(root):\n","        root = Path(os.path.abspath(root))\n","\n","    if not os.path.isabs(destination):\n","        destination = Path(os.path.abspath(destination))\n","\n","    if not os.path.exists(destination):\n","        os.mkdir(destination)\n","\n","    # Loop and move files from MusicNet into a train folder grouped by \"groupby\"\n","    train_dir = root / \"train_data\"\n","    test_dir = root / \"test_data\"\n","    for group_name, group_df in tqdm(metadata.groupby(groupby), disable=disable_progress_bar):\n","        group_ids = group_df.id.tolist()\n","\n","        out_dir = destination / f\"{group_name.replace(' ', '_')}\"\n","        if not os.path.exists(out_dir):\n","            os.mkdir(out_dir)\n","        \n","        for fid in group_ids:\n","            \n","            fname = train_dir / f\"{fid}.wav\"\n","            if not fname.exists():\n","                fname = test_dir / f\"{fid}.wav\"\n","            \n","            copy(str(fname), str(out_dir))\n","\n","    print(f\"Curated data at {destination}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tp2C229gcD_t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618771363732,"user_tz":240,"elapsed":422378,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"cca6ec7e-16c1-4012-ebdd-1ee911acca8d"},"source":["# parsed_dir = Path(\"musicnet/parsed\")\n","# curate_data(root, parsed_dir, metadata, 'composer')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Curated data to /content/musicnet/parsed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C93EraxkwkAz"},"source":["def parse_data(src, dst, domains):\n","    \"\"\"\n","    Extract the desired domains from the raw MusicNet files\n","\n","    Parameters\n","    ----------\n","    src: str\n","        Path to input data (e.g. /content/musicnet)\n","        \n","    \"\"\"\n","\n","    dst.mkdir(exist_ok=True, parents=True)\n","    \n","    db = pd.read_csv( src / 'musicnet_metadata.csv')\n","    traindir = src / 'train_data'\n","    testdir = src /'test_data'\n","\n","    for (ensemble, composer) in domains:\n","        fid_list = db[(db[\"composer\"] == composer) & (db[\"ensemble\"] == ensemble)].id.tolist()\n","        total_time = sum(db[(db[\"composer\"] == composer) & (db[\"ensemble\"] == ensemble)].seconds.tolist())\n","        print(f\"Total time for {composer} with {ensemble} is: {total_time} seconds\")\n","\n","\n","        domaindir = dst / f\"{composer}_{ensemble.replace(' ', '_')}\"\n","        if not os.path.exists(domaindir):\n","            os.mkdir(domaindir)\n","\n","        for fid in fid_list:\n","            fname = traindir / f'{fid}.wav'\n","            if not fname.exists():\n","                fname = testdir / f'{fid}.wav'\n","\n","            copy(str(fname), str(domaindir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uIbYTn1wmYQ"},"source":["domains = [\n","        ['Accompanied Violin', 'Beethoven'],\n","        ['Solo Cello', 'Bach'],\n","        ['Solo Piano', 'Bach'],\n","        ['Solo Piano', 'Beethoven'],\n","        ['String Quartet', 'Beethoven'],\n","        ['Wind Quintet', 'Cambini'],\n","    ]\n","src_path = Path('/content/musicnet')\n","dst_path = Path('/content/musicnet/parsed')\n","parse_data(src_path, dst_path, domains)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dByR8_KsbEmv"},"source":["### DataLoader Class\n","\n","`TODO`: Adapt data wrapper class for easy I/O with WaveNet data\n","- `TODO 1`: Get this working for raw WaveNet dataset\n","- `TODO 2`: Get this working for composer subdirectory structure\n","\n","Silu's Notes:\n","- Removed augmentation, other unnecessary params\n","- Changed to encoded dataset\n","- Left TODOs below\n"]},{"cell_type":"code","metadata":{"id":"wo8BSHe8b_Sq"},"source":["# UMT: utils.py\n","class timeit:\n","    def __init__(self, name, logger=None):\n","        self.name = name\n","        self.logger = logger\n","\n","    def __enter__(self):\n","        self.start = time.time()\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        if self.logger is None:\n","            print(f'{self.name} took {(time.time() - self.start) * 1000} ms')\n","        else:\n","            self.logger.debug('%s took %s ms', self.name, (time.time() - self.start) * 1000)\n","\n","\n","def mu_law(x, mu=255):\n","    x = numpy.clip(x, -1, 1)\n","    x_mu = numpy.sign(x) * numpy.log(1 + mu*numpy.abs(x))/numpy.log(1 + mu)\n","    return ((x_mu + 1)/2 * mu).astype('int16')\n","\n","\n","def inv_mu_law(x, mu=255.0):\n","    x = numpy.array(x).astype(numpy.float32)\n","    y = 2. * (x - (mu+1.)/2.) / (mu+1.)\n","    return numpy.sign(y) * (1./mu) * ((1. + mu)**numpy.abs(y) - 1.)\n","\n","\n","class LossMeter(object):\n","    def __init__(self, name):\n","        self.name = name\n","        self.losses = []\n","\n","    def reset(self):\n","        self.losses = []\n","\n","    def add(self, val):\n","        self.losses.append(val)\n","\n","    def summarize_epoch(self):\n","        if self.losses:\n","            return np.mean(self.losses)\n","        else:\n","            return 0\n","\n","    def sum(self):\n","        return sum(self.losses)\n","\n","\n","class LogFormatter:\n","    def __init__(self):\n","        self.start_time = time.time()\n","\n","    def format(self, record):\n","        elapsed_seconds = round(record.created - self.start_time)\n","\n","        prefix = \"%s - %s - %s\" % (\n","            record.levelname,\n","            time.strftime('%x %X'),\n","            timedelta(seconds=elapsed_seconds)\n","        )\n","        message = record.getMessage()\n","        message = message.replace('\\n', '\\n' + ' ' * (len(prefix) + 3))\n","        return \"%s - %s\" % (prefix, message)\n","\n","\n","def create_output_dir(opt, path: Path):\n","    if hasattr(opt, 'rank'):\n","        filepath = path / f'main_{opt.rank}.log'\n","    else:\n","        filepath = path / 'main.log'\n","\n","    if not path.exists():\n","        path.mkdir(parents=True, exist_ok=True)\n","\n","    if hasattr(opt, 'rank') and opt.rank != 0:\n","        sys.stdout = open(path / f'stdout_{opt.rank}.log', 'w')\n","        sys.stderr = open(path / f'stderr_{opt.rank}.log', 'w')\n","\n","    # Safety check\n","    if filepath.exists() and not opt.checkpoint:\n","        logging.warning(\"Experiment already exists!\")\n","\n","    # Create log formatter\n","    log_formatter = LogFormatter()\n","\n","    # Create logger and set level to debug\n","    logger = logging.getLogger()\n","    logger.handlers = []\n","    logger.setLevel(logging.DEBUG)\n","    logger.propagate = False\n","\n","    # create file handler and set level to debug\n","    file_handler = logging.FileHandler(filepath, \"a\")\n","    file_handler.setLevel(logging.DEBUG)\n","    file_handler.setFormatter(log_formatter)\n","    logger.addHandler(file_handler)\n","\n","    # create console handler and set level to info\n","    if hasattr(opt, 'rank') and opt.rank == 0:\n","        console_handler = logging.StreamHandler()\n","        console_handler.setLevel(logging.INFO)\n","        console_handler.setFormatter(log_formatter)\n","        logger.addHandler(console_handler)\n","\n","    # reset logger elapsed time\n","    def reset_time():\n","        log_formatter.start_time = time.time()\n","    logger.reset_time = reset_time\n","\n","    logger.info(opt)\n","    return logger\n","\n","\n","def setup_logger(logger_name, filename):\n","    logger = logging.getLogger(logger_name)\n","    logger.handlers = []\n","    logger.setLevel(logging.DEBUG)\n","    logger.propagate = False\n","\n","    stderr_handler = logging.StreamHandler(sys.stderr)\n","    file_handler = logging.FileHandler(filename)\n","    file_handler.setLevel(logging.DEBUG)\n","    if \"RANK\" in os.environ and os.environ[\"RANK\"] != \"0\":\n","        stderr_handler.setLevel(logging.WARNING)\n","    else:\n","        stderr_handler.setLevel(logging.INFO)\n","    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n","    stderr_handler.setFormatter(formatter)\n","    file_handler.setFormatter(formatter)\n","    logger.addHandler(stderr_handler)\n","    logger.addHandler(file_handler)\n","    return logger\n","\n","\n","def wrap(data, **kwargs):\n","    if torch.is_tensor(data):\n","        var = data.cuda(non_blocking=True)\n","        return var\n","    else:\n","        return tuple([wrap(x, **kwargs) for x in data])\n","\n","\n","def save_audio(x, path, rate):\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    wavfile.write(path, rate, x)\n","\n","\n","def save_wav_image(wav, path):\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    plt.figure(figsize=(15, 5))\n","    plt.plot(wav)\n","    plt.savefig(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7h2eEJtw5G1"},"source":["# UMT: data.py\n","logger = setup_logger(__name__, 'data.log')\n","\n","\n","def random_of_length(seq, length):\n","    limit = seq.size(0) - length\n","    if length < 1:\n","        # logging.warning(\"%d %s\" % (length, path))\n","        return None\n","\n","    start = random.randint(0, limit)\n","    end = start + length\n","    return seq[start: end]\n","\n","\n","class EncodedFilesDataset(data.Dataset):\n","    \"\"\"\n","    Uses ffmpeg to read a random short segment from the middle of an encoded file\n","    \"\"\"\n","    FILE_TYPES = ['mp3', 'ape', 'm4a', 'flac', 'mkv', 'wav']\n","    WAV_FREQ = 16000\n","    INPUT_FREQ = 44100\n","    FFT_SZ = 2048\n","    WINLEN = FFT_SZ - 1\n","    HOP_SZ = 80\n","\n","    def __init__(self, top, seq_len=None, file_type=None, epoch_len=10000):\n","        self.path = Path(top)\n","        self.seq_len = seq_len\n","        self.file_types = [file_type] if file_type else self.FILE_TYPES\n","        self.file_paths = self.filter_paths(self.path.glob('**/*'), self.file_types)\n","        self.epoch_len = epoch_len\n","\n","    @staticmethod\n","    def filter_paths(haystack, file_types):\n","        return [f for f in haystack\n","                if (f.is_file()\n","                    and any(f.name.endswith(suffix) for suffix in file_types)\n","                    and '__MACOSX' not in f.parts)]\n","\n","    def _random_file(self):\n","        # return np.random.choice(self.file_paths, p=self.probs)\n","        return random.choice(self.file_paths)\n","\n","    @staticmethod\n","    def _file_length(file_path):\n","        output = subprocess.run(['ffprobe',\n","                                 '-show_entries', 'format=duration',\n","                                 '-v', 'quiet',\n","                                 '-print_format', 'compact=print_section=0:nokey=1:escape=csv',\n","                                 str(file_path)],\n","                                stdout=subprocess.PIPE,\n","                                stderr=subprocess.PIPE).stdout\n","        duration = float(output)\n","\n","        return duration\n","\n","    def _file_slice(self, file_path, start_time):\n","        length_sec = self.seq_len / self.WAV_FREQ\n","        length_sec += .01  # just in case\n","        with NamedTemporaryFile() as output_file:\n","            output = subprocess.run(['ffmpeg',\n","                                     '-v', 'quiet',\n","                                     '-y',  # overwrite\n","                                     '-ss', str(start_time),\n","                                     '-i', str(file_path),\n","                                     '-t', str(length_sec),\n","                                     '-f', 'wav',\n","                                     # '-af', 'dynaudnorm',\n","                                     '-ar', str(self.WAV_FREQ),  # audio rate\n","                                     '-ac', '1',  # audio channels\n","                                     output_file.name\n","                                     ],\n","                                    stdout=subprocess.PIPE,\n","                                    stderr=subprocess.PIPE).stdout\n","            rate, wav_data = wavfile.read(output_file)\n","            assert wav_data.dtype == np.int16\n","            wav = wav_data[:self.seq_len].astype('float')\n","\n","            return wav\n","\n","    def __len__(self):\n","        return self.epoch_len\n","\n","    def __getitem__(self, _):\n","        wav = self.random_file_slice()\n","        return torch.FloatTensor(wav)\n","\n","    def random_file_slice(self):\n","        wav_data = None\n","\n","        while wav_data is None or len(wav_data) != self.seq_len:\n","            try:\n","                file, file_length_sec, start_time, wav_data = self.try_random_file_slice()\n","            except Exception as e:\n","                logger.exception('Exception %s in random_file_slice.', e)\n","\n","        # logger.debug('Sample: File: %s, File length: %s, Start time: %s',\n","        #              file, file_length_sec, start_time)\n","\n","        return wav_data\n","\n","    def try_random_file_slice(self):\n","        file = self._random_file()\n","        file_length_sec = self._file_length(file)\n","        segment_length_sec = self.seq_len / self.WAV_FREQ\n","        if file_length_sec < segment_length_sec:\n","            logger.warn('File \"%s\" has length %s, segment length is %s',\n","                        file, file_length_sec, segment_length_sec)\n","\n","        start_time = random.random() * (file_length_sec - segment_length_sec * 2)  # just in case\n","        try:\n","            wav_data = self._file_slice(file, start_time)\n","        except Exception as e:\n","            logger.info(f'Exception in file slice: {e}. '\n","                        f'File: {file}, '\n","                        f'File length: {file_length_sec}, '\n","                        f'Start time: {start_time}')\n","            raise\n","\n","        if len(wav_data) != self.seq_len:\n","            logger.warn('File \"%s\" has length %s, segment length is %s, wav data length: %s',\n","                        file, file_length_sec, segment_length_sec, len(wav_data))\n","\n","        return file, file_length_sec, start_time, wav_data\n","\n","    def dump_to_folder(self, output: Path, norm_db=False):\n","        for file_path in tqdm(self.file_paths):\n","            output_file_path = output / file_path.relative_to(self.path).with_suffix('.h5')\n","            output_file_path.parent.mkdir(parents=True, exist_ok=True)\n","            with NamedTemporaryFile(suffix='.wav') as output_wav_file, \\\n","                    NamedTemporaryFile(suffix='.wav') as norm_file_path, \\\n","                    NamedTemporaryFile(suffix='.wav') as wav_convert_file:\n","                if norm_db:\n","                    logger.debug(f'Converting {file_path} to {wav_convert_file.name}')\n","                    subprocess.run(['ffmpeg',\n","                                    '-y',\n","                                    '-i', file_path,\n","                                    wav_convert_file.name],\n","                                   stdout=subprocess.PIPE,\n","                                   stderr=subprocess.PIPE)\n","\n","                    logger.debug(f'Companding {wav_convert_file.name} to {norm_file_path.name}')\n","                    subprocess.run(['sox',\n","                                    '-G',\n","                                    wav_convert_file.name,\n","                                    norm_file_path.name,\n","                                    'compand',\n","                                    '0.3,1',\n","                                    '6:-70,-60,-20',\n","                                    '-5',\n","                                    '-90',\n","                                    '0.2'],\n","                                   stdout=subprocess.PIPE,\n","                                   stderr=subprocess.PIPE)\n","                    input_file_path = norm_file_path.name\n","                else:\n","                    input_file_path = file_path\n","\n","                logger.debug(f'Converting {input_file_path} to {output_wav_file.name}')\n","                subprocess.run(['ffmpeg',\n","                                '-v', 'quiet',\n","                                '-y',  # overwrite\n","                                '-i', input_file_path,\n","                                # '-af', 'dynaudnorm',\n","                                '-f', 'wav',\n","                                '-ar', str(self.WAV_FREQ),  # audio rate\n","                                '-ac', '1',  # audio channels,\n","                                output_wav_file.name\n","                                ],\n","                               stdout=subprocess.PIPE,\n","                               stderr=subprocess.PIPE)\n","                try:\n","                    rate, wav_data = wavfile.read(output_wav_file.name)\n","                except ValueError:\n","                    logger.info(f'Cannot read {file_path} wav conversion')\n","                    raise\n","                    # raise\n","                assert wav_data.dtype == np.int16\n","                wav = wav_data.astype('float')\n","\n","                with h5py.File(output_file_path, 'w') as output_file:\n","                    chunk_shape = (min(10000, len(wav)),)\n","                    wav_dset = output_file.create_dataset('wav', wav.shape, dtype=wav.dtype,\n","                                                          chunks=chunk_shape)\n","                    wav_dset[...] = wav\n","\n","                logger.debug(f'Saved input {file_path} to {output_file_path}. '\n","                             f'Wav length: {wav.shape}')\n","\n","\n","class H5Dataset(data.Dataset):\n","    def __init__(self, top, seq_len, dataset_name, epoch_len=10000, augmentation=None, short=False,\n","                 whole_samples=False, cache=False):\n","        self.path = Path(top)\n","        self.seq_len = seq_len\n","        self.epoch_len = epoch_len\n","        self.short = short\n","        self.whole_samples = whole_samples\n","        self.augmentation = augmentation\n","        self.dataset_name = dataset_name\n","\n","        self.file_paths = list(self.path.glob('**/*.h5'))\n","        if self.short:\n","            self.file_paths = [self.file_paths[0]]\n","\n","        self.data_cache = {}\n","        if cache:\n","            for file_path in tqdm(self.file_paths,\n","                                       desc=f'Reading dataset {top.parent.name}/{top.name}'):\n","                dataset = self.read_h5_file(file_path)\n","                self.data_cache[file_path] = dataset[:]\n","\n","        if not self.file_paths:\n","            logger.error(f'No files found in {self.path}')\n","\n","        logger.info(f'Dataset created. {len(self.file_paths)} files, '\n","                    f'augmentation: {self.augmentation is not None}. '\n","                    f'Path: {self.path}')\n","\n","    def __getitem__(self, _):\n","        ret = None\n","        while ret is None:\n","            try:\n","                ret = self.try_random_slice()\n","                if self.augmentation:\n","                    ret = [ret, self.augmentation(ret)]\n","                else:\n","                    ret = [ret, ret]\n","\n","                if self.dataset_name == 'wav':\n","                    ret = [mu_law(x / 2 ** 15) for x in ret]\n","            except Exception as e:\n","                logger.info('Exception %s in dataset __getitem__, path %s', e, self.path)\n","                logger.debug('Exception in H5Dataset', exc_info=True)\n","\n","        return torch.tensor(ret[0]), torch.tensor(ret[1])\n","\n","    def try_random_slice(self):\n","        h5file_path = random.choice(self.file_paths)\n","        if h5file_path in self.data_cache:\n","            dataset = self.data_cache[h5file_path]\n","        else:\n","            dataset = self.read_h5_file(h5file_path)\n","        return self.read_wav_data(dataset, h5file_path)\n","\n","    def read_h5_file(self, h5file_path):\n","        try:\n","            f = h5py.File(h5file_path, 'r')\n","        except Exception as e:\n","            logger.exception('Failed opening %s', h5file_path)\n","            raise\n","\n","        try:\n","            dataset = f[self.dataset_name]\n","        except Exception:\n","            logger.exception(f'No dataset named {self.dataset_name} in {file_path}. '\n","                             f'Available datasets are: {list(f.keys())}.')\n","\n","        return dataset\n","\n","    def read_wav_data(self, dataset, path):\n","        if self.whole_samples:\n","            data = dataset[:]\n","        else:\n","            length = dataset.shape[0]\n","\n","            if length <= self.seq_len:\n","                logger.debug('Length of %s is %s', path, length)\n","\n","            start_time = random.randint(0, length - self.seq_len)\n","            data = dataset[start_time: start_time + self.seq_len]\n","            assert data.shape[0] == self.seq_len\n","\n","        return data.T\n","\n","    def __len__(self):\n","        return self.epoch_len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ay6ef1FS79s"},"source":["def copy_files(files, from_path, to_path: Path):\n","    for f in files:\n","        out_file_path = to_path / f.relative_to(from_path)\n","        out_file_path.parent.mkdir(parents=True, exist_ok=True)\n","        copy(f, out_file_path)\n","    \n","def move_files(files, from_path, to_path: Path):\n","    for f in files:\n","        out_file_path = to_path / f.relative_to(from_path)\n","        out_file_path.parent.mkdir(parents=True, exist_ok=True)\n","        move(f, out_file_path)\n","\n","def split(input_path, output_path, train_ratio=0.8, val_ratio=0.1, copy=False, filetype=None):\n","    if filetype:\n","        filetypes = [filetype]\n","    else:\n","        filetypes = EncodedFilesDataset.FILE_TYPES\n","    \n","    input_files = EncodedFilesDataset.filter_paths(input_path.glob('**/*'), filetypes)\n","    random.shuffle(input_files)\n","\n","    logger.info(f\"Found {len(input_files)} files\")\n","\n","    n_train = int(len(input_files) * train_ratio)\n","    n_val = int(len(input_files) * val_ratio)\n","    if n_val == 0:\n","        n_val = 1\n","    n_test = len(input_files) - n_train - n_val\n","\n","    logger.info(f'Split as follows: Train - {n_train}, Validation - {n_val}, Test - {n_test}')\n","    assert n_test > 0\n","\n","    if copy:\n","        copy_files(input_files[:n_train], input_path, output_path / 'train')\n","        copy_files(input_files[n_train:n_train + n_val], input_path, output_path / 'val')\n","        copy_files(input_files[n_train + n_val:], input_path, output_path / 'test')\n","    else:\n","        move_files(input_files[:n_train], input_path, output_path / 'train')\n","        move_files(input_files[n_train:n_train + n_val], input_path, output_path / 'val')\n","        move_files(input_files[n_train + n_val:], input_path, output_path / 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_LMrL4OS_PH","executionInfo":{"status":"ok","timestamp":1618772448248,"user_tz":240,"elapsed":415,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"0481b01f-ca2f-4311-c8d4-4c4aff889c90"},"source":["random.seed(1234)\n","splitdir = Path('/content/musicnet/split')\n","\n","for input_path in dst_path.glob(\"*/\"):\n","    basename = os.path.basename(input_path)\n","    output_path = Path(splitdir / basename)\n","    split(input_path, output_path, filetype='wav', copy=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n","Found 0 files\n","Split as follows: Train - 0, Validation - 1, Test - -1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9L6TqyceVdYv","executionInfo":{"status":"ok","timestamp":1618772964020,"user_tz":240,"elapsed":497367,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"af09e40c-11b6-4948-d89f-7507b932b493"},"source":["def preprocess(input_path, output_path, norm_db=False):\n","    dataset = EncodedFilesDataset(input_path)\n","    dataset.dump_to_folder(output_path, norm_db=norm_db)\n","    print('Preprocessing complete')\n","\n","preprocessed_dir = Path('/content/musicnet/preprocessed')\n","preprocess(splitdir, preprocessed_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 330/330 [08:16<00:00,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["Preprocessing complete\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nd2PbL31YJxP","executionInfo":{"status":"ok","timestamp":1618772984415,"user_tz":240,"elapsed":265,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"2b222d21-5192-41dd-c8fc-5008e77fb2e3"},"source":["print(*preprocessed_dir.glob('*/'), sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/musicnet/preprocessed/Beethoven\n","/content/musicnet/preprocessed/Brahms\n","/content/musicnet/preprocessed/Cambini\n","/content/musicnet/preprocessed/Mozart\n","/content/musicnet/preprocessed/Haydn\n","/content/musicnet/preprocessed/Ravel\n","/content/musicnet/preprocessed/Faure\n","/content/musicnet/preprocessed/Dvorak\n","/content/musicnet/preprocessed/Schubert\n","/content/musicnet/preprocessed/Bach\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mayCHMS_YwqY"},"source":["class WavFrequencyAugmentation:\n","    def __init__(self, wav_freq, magnitude=0.5):\n","        self.magnitude = magnitude\n","        self.wav_freq = wav_freq\n","\n","    def __call__(self, wav):\n","        length = wav.shape[0]\n","        perturb_length = random.randint(length // 4, length // 2)\n","        perturb_start = random.randint(0, length // 2)\n","        perturb_end = perturb_start + perturb_length\n","        pitch_perturb = (np.random.rand() - 0.5) * 2 * self.magnitude\n","\n","        ret = np.concatenate([wav[:perturb_start],\n","                              librosa.effects.pitch_shift(wav[perturb_start:perturb_end],\n","                                                          self.wav_freq, pitch_perturb),\n","                              wav[perturb_end:]])\n","\n","        return ret\n","\n","\n","class DatasetSet:\n","    # Default values are from UMT train.py argparser\n","    def __init__(self, dir: Path, seq_len, batch_size=32, num_workers=10, data_aug='store_true', magnitude=0.5, h5_dataset_name='wav', short='store_true'):\n","        if data_aug:\n","            # augmentation = WavFrequencyAugmentation(EncodedFilesDataset.WAV_FREQ, args.magnitude)\n","            augmentation = WavFrequencyAugmentation(EncodedFilesDataset.WAV_FREQ, magnitude)\n","        else:\n","            augmentation = None\n","\n","        # Original epoch_len = 10000000000\n","        # self.train_dataset = H5Dataset(dir / 'train', seq_len, epoch_len=10000000000,\n","        #                                dataset_name=args.h5_dataset_name, augmentation=augmentation,\n","        #                                short=args.short, cache=False)\n","        self.train_dataset = H5Dataset(dir / 'train', seq_len, epoch_len=1000000,\n","                                       dataset_name=h5_dataset_name, augmentation=augmentation,\n","                                       short=short, cache=False)\n","        # self.train_loader = data.DataLoader(self.train_dataset,\n","        #                                     batch_size=args.batch_size,\n","        #                                     num_workers=args.num_workers,\n","        #                                     pin_memory=True)\n","        self.train_loader = data.DataLoader(self.train_dataset,\n","                                            batch_size=batch_size,\n","                                            num_workers=num_workers,\n","                                            pin_memory=True)\n","        \n","\n","        self.train_iter = iter(self.train_loader)\n","\n","        # Original epoch_len = 1000000000\n","        # self.valid_dataset = H5Dataset(dir / 'val', seq_len, epoch_len=100000,\n","        #                                dataset_name=args.h5_dataset_name, augmentation=augmentation,\n","        #                                short=args.short)\n","        self.valid_dataset = H5Dataset(dir / 'val', seq_len, epoch_len=100000,\n","                                       dataset_name=h5_dataset_name, augmentation=augmentation,\n","                                       short=short)\n","        # self.valid_loader = data.DataLoader(self.valid_dataset,\n","        #                                     batch_size=args.batch_size,\n","        #                                     num_workers=arg.snum_workers // 10 + 1,\n","        #                                     pin_memory=True)\n","        self.valid_loader = data.DataLoader(self.valid_dataset,\n","                                            batch_size=batch_size,\n","                                            num_workers=num_workers // 10 + 1,\n","                                            pin_memory=True)\n","\n","        self.valid_iter = iter(self.valid_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GSnQHGO3YgA"},"source":["# UMT: train.sh arguments\n","kwargs = dict(seq_len=12000, batch_size=32, num_workers=2)\n","dataset = [DatasetSet(d, **kwargs) for d in preprocessed_dir.glob(\"*/\")]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WFKG4eM6Y5tr"},"source":["## 2. CPC Sandbox"]},{"cell_type":"code","metadata":{"id":"xY_w4u7p3_aZ"},"source":["from __future__ import print_function\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import math\n","\n","## PyTorch implementation of CDCK2 speaker classifier models\n","# CDCK2: base model from the paper 'Representation Learning with Contrastive Predictive Coding'\n","# SpkClassifier: a simple NN for speaker classification\n","\n","class CDCK2(nn.Module):\n","    def __init__(self, timestep, batch_size, seq_len):\n","\n","        super(CDCK2, self).__init__()\n","\n","        self.batch_size = batch_size\n","        self.seq_len = seq_len\n","        self.timestep = timestep\n","        self.encoder = nn.Sequential( # downsampling factor = 160\n","            nn.Conv1d(1, 512, kernel_size=10, stride=5, padding=3, bias=False),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv1d(512, 512, kernel_size=8, stride=4, padding=2, bias=False),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv1d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv1d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv1d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.gru = nn.GRU(512, 256, num_layers=1, bidirectional=False, batch_first=True)\n","        self.Wk  = nn.ModuleList([nn.Linear(256, 512) for i in range(timestep)])\n","        self.softmax  = nn.Softmax()\n","        self.lsoftmax = nn.LogSoftmax()\n","\n","        def _weights_init(m):\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm1d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # initialize gru\n","        for layer_p in self.gru._all_weights:\n","            for p in layer_p:\n","                if 'weight' in p:\n","                    nn.init.kaiming_normal_(self.gru.__getattr__(p), mode='fan_out', nonlinearity='relu')\n","\n","        self.apply(_weights_init)\n","\n","    def init_hidden(self, batch_size, use_gpu=True):\n","        if use_gpu: return torch.zeros(1, batch_size, 256).cuda()\n","        else: return torch.zeros(1, batch_size, 256)\n","\n","    def forward(self, x, hidden):\n","        batch = x.size()[0]\n","\n","        # Encoder downsamples x by 160\n","        # t_samples is a random index into the encoded sequence z\n","        t_samples = torch.randint(self.seq_len // 160 - self.timestep, size=(1,)).long() # randomly pick a time stamp\n","\n","        # input sequence is N*C*L, e.g. 8*1*20480\n","        z = self.encoder(x)\n","        # encoded sequence is N*C*L, e.g. 8*512*128\n","        # reshape to N*L*C for GRU, e.g. 8*128*512\n","        z = z.transpose(1,2)\n","        encode_samples = torch.empty((self.timestep, batch, 512)).float() # e.g. size 12*8*512\n","        for k in np.arange(1, self.timestep+1):\n","            encode_samples[k-1] = z[:,t_samples+k,:].view(batch, 512) # z_t+k e.g. size 8*512\n","        forward_seq = z[:,:t_samples+1,:] # e.g. size 8*100*512\n","        output, hidden = self.gru(forward_seq, hidden) # output size e.g. 8*100*256\n","        c_t = output[:,t_samples,:].view(batch, 256) # c_t e.g. size 8*256\n","        pred = torch.empty((self.timestep, batch, 512)).float() # e.g. size 12*8*512\n","        for i in np.arange(self.timestep):\n","            linear = self.Wk[i]\n","            pred[i] = linear(c_t) # Wk*c_t e.g. size 8*512\n","        \n","        # InfoNCELoss -- we will likely want to separate this out\n","        nce = 0 # average over timestep and batch\n","        correct = 0\n","        for i in np.arange(self.timestep):\n","            total = torch.mm(encode_samples[i], torch.transpose(pred[i], 0, 1)) # e.g. size 8*8\n","            correct += torch.sum(torch.eq(torch.argmax(self.softmax(total), dim=0), torch.arange(0, batch))) # correct is a tensor\n","            nce += torch.sum(torch.diag(self.lsoftmax(total))) # nce is a tensor\n","        nce /= -1.*batch*self.timestep\n","        accuracy = 1.*correct.item()/(batch * self.timestep)\n","\n","        return accuracy, nce, hidden\n","\n","    def predict(self, x, hidden):\n","        batch = x.size()[0]\n","        # input sequence is N*C*L, e.g. 8*1*20480\n","        z = self.encoder(x)\n","        # encoded sequence is N*C*L, e.g. 8*512*128\n","        # reshape to N*L*C for GRU, e.g. 8*128*512\n","        z = z.transpose(1, 2)\n","        output, hidden = self.gru(z, hidden) # output size e.g. 8*128*256\n","\n","        return output, hidden # return every frame\n","        #return output[:,-1,:], hidden # only return the last frame per utt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EpMUaaN5sbD"},"source":["class InfoNCELoss(nn.Module):\n","    \"\"\"Separate NCE loss class from CPC model\n","    \"\"\"\n","    def __init__(self, *args):\n","        super(InfoNCELoss, self).__init__()\n","    \n","    def forward(self, x):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGEyShqFY3y0"},"source":["class SpkClassifier(nn.Module):\n","    ''' linear classifier '''\n","    def __init__(self, spk_num):\n","\n","        super(SpkClassifier, self).__init__()\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(256, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, spk_num)\n","            #nn.Linear(256, spk_num)\n","        )\n","\n","        def _weights_init(m):\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm1d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        self.apply(_weights_init)\n","\n","    def forward(self, x):\n","        x = self.classifier(x)\n","\n","        return F.log_softmax(x, dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTlJ13gYIRcz"},"source":["### Running CPC on one sample"]},{"cell_type":"code","metadata":{"id":"cP7vHPKc84zr"},"source":["file_id = 2186\n","\n","samplerate, sample = wavfile.read(f'/content/musicnet/train/Bach/data/{file_id}.wav')\n","\n","batch_size = 1\n","seq_len = 20480\n","\n","sample = sample[:seq_len].copy()\n","sample = torch.from_numpy(sample)\n","sample = sample.view(1, 1, *sample.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6GaPoYF7cbb","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1618644765045,"user_tz":240,"elapsed":453,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"1e1270fd-61ef-43c3-d637-573e38035c6b"},"source":["labels = pd.read_csv(f'/content/musicnet/train/Bach/labels/{file_id}.csv')\n","labels.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>start_time</th>\n","      <th>end_time</th>\n","      <th>instrument</th>\n","      <th>note</th>\n","      <th>start_beat</th>\n","      <th>end_beat</th>\n","      <th>note_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45534</td>\n","      <td>55262</td>\n","      <td>41</td>\n","      <td>88</td>\n","      <td>0.50</td>\n","      <td>0.239583</td>\n","      <td>Sixteenth</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>55774</td>\n","      <td>60893</td>\n","      <td>41</td>\n","      <td>87</td>\n","      <td>0.75</td>\n","      <td>0.239583</td>\n","      <td>Sixteenth</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>61406</td>\n","      <td>71646</td>\n","      <td>41</td>\n","      <td>88</td>\n","      <td>1.00</td>\n","      <td>0.489583</td>\n","      <td>Eighth</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>71646</td>\n","      <td>83422</td>\n","      <td>41</td>\n","      <td>83</td>\n","      <td>1.50</td>\n","      <td>0.489583</td>\n","      <td>Eighth</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>83934</td>\n","      <td>96222</td>\n","      <td>41</td>\n","      <td>80</td>\n","      <td>2.00</td>\n","      <td>0.489583</td>\n","      <td>Eighth</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   start_time  end_time  instrument  note  start_beat  end_beat note_value\n","0       45534     55262          41    88        0.50  0.239583  Sixteenth\n","1       55774     60893          41    87        0.75  0.239583  Sixteenth\n","2       61406     71646          41    88        1.00  0.489583     Eighth\n","3       71646     83422          41    83        1.50  0.489583     Eighth\n","4       83934     96222          41    80        2.00  0.489583     Eighth"]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"code","metadata":{"id":"VXqdTYr0-egY"},"source":["def train(model, sample, optimizer):\n","    model.train()\n","    #sample = sample.float().unsqueeze(1).cuda() # add channel dimension\n","    sample = sample.float()\n","\n","    optimizer.zero_grad()\n","    hidden = model.init_hidden(len(sample), use_gpu=False)\n","    acc, loss, hidden = model(sample, hidden)\n","\n","    print(acc, loss)\n","\n","    loss.backward()\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PK2OnI0v-4X","executionInfo":{"status":"ok","timestamp":1618644869472,"user_tz":240,"elapsed":1088,"user":{"displayName":"Chester Huynh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2BRT271skWdp-WWHqZJnCWuewZ2iADwpruJyt_Q=s64","userId":"07499809855745885442"}},"outputId":"0a7df821-26db-4704-8b9d-2defa8e72275"},"source":["model = CDCK2(12, 1, seq_len)\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","train(model, sample, optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["1.0 tensor(-0., grad_fn=<DivBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wcOPaNEUwG0V"},"source":[""],"execution_count":null,"outputs":[]}]}